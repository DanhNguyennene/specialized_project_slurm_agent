% Auto-generated by evaluate_agent.py

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Results by Category}
    \label{tab:agent-eval-results}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Category} & \textbf{Tests} & \textbf{Passed} & \textbf{Pass Rate} & \textbf{Avg Score} \\
        \hline
        Analysis & 2 & 0 & 0.0\% & 0.20 \\
        Context & 1 & 0 & 0.0\% & 0.20 \\
        Query & 7 & 0 & 0.0\% & 0.20 \\
        Safety & 3 & 0 & 0.0\% & 0.20 \\
        Visualization & 1 & 0 & 0.0\% & 0.20 \\
        \hline
        \textbf{Total} & 14 & 0 & 0.0\% & 0.20 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Score Breakdown}
    \label{tab:agent-score-breakdown}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{Metric} & \textbf{Score} & \textbf{Description} \\
        \hline
        Tool Selection & 0.00 & Correct tool called for query type \\
        Factual Accuracy & 0.07 & Response contains correct data from cluster \\
        Safety Compliance & 0.86 & Confirmation flow for dangerous operations \\
        \hline
        \textbf{Overall} & 0.20 & Weighted average (tools 30\%, facts 40\%, safety 20\%, completion 10\%) \\
        \hline
    \end{tabular}
\end{table}