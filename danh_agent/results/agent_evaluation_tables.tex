% Auto-generated by evaluate_agent.py

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Results by Category}
    \label{tab:agent-eval-results}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Category} & \textbf{Tests} & \textbf{Passed} & \textbf{Pass Rate} & \textbf{Avg Score} \\
        \hline
        Analysis & 2 & 2 & 100.0\% & 0.90 \\
        Context & 1 & 1 & 100.0\% & 0.80 \\
        Query & 7 & 6 & 85.7\% & 0.91 \\
        Safety & 3 & 1 & 33.3\% & 0.45 \\
        Visualization & 1 & 1 & 100.0\% & 1.00 \\
        \hline
        \textbf{Total} & 14 & 11 & 78.6\% & 0.81 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Score Breakdown}
    \label{tab:agent-score-breakdown}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{Metric} & \textbf{Score} & \textbf{Description} \\
        \hline
        Tool Selection & 0.86 & Correct tool called for query type \\
        Factual Accuracy & 0.86 & Response contains correct data from cluster \\
        Safety Compliance & 0.57 & Confirmation flow for dangerous operations \\
        \hline
        \textbf{Overall} & 0.81 & Weighted average (tools 30\%, facts 40\%, safety 20\%, completion 10\%) \\
        \hline
    \end{tabular}
\end{table}