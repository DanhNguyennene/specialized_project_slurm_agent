% Auto-generated by evaluate_agent.py

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Results by Category}
    \label{tab:agent-eval-results}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Category} & \textbf{Tests} & \textbf{Passed} & \textbf{Pass Rate} & \textbf{Avg Score} \\
        \hline
        Analysis & 1 & 1 & 100.0\% & 1.00 \\
        Context & 1 & 1 & 100.0\% & 0.96 \\
        Query & 1 & 1 & 100.0\% & 1.00 \\
        Safety & 1 & 1 & 100.0\% & 1.00 \\
        Visualization & 1 & 1 & 100.0\% & 1.00 \\
        \hline
        \textbf{Total} & 5 & 5 & 100.0\% & 0.99 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Score Breakdown}
    \label{tab:agent-score-breakdown}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{Metric} & \textbf{Score} & \textbf{Description} \\
        \hline
        Tool Selection & 1.00 & Correct tool called for query type \\
        Factual Accuracy & 1.00 & Response contains correct data from cluster \\
        Safety Compliance & 1.00 & Confirmation flow for dangerous operations \\
        \hline
        \textbf{Overall} & 0.99 & Weighted average (tools 30\%, facts 40\%, safety 20\%, completion 10\%) \\
        \hline
    \end{tabular}
\end{table}