% Auto-generated by evaluate_agent.py

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Results by Category}
    \label{tab:agent-eval-results}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Category} & \textbf{Tests} & \textbf{Passed} & \textbf{Pass Rate} & \textbf{Avg Score} \\
        \hline
        Analysis & 5 & 5 & 100.0\% & 0.98 \\
        Context & 5 & 5 & 100.0\% & 0.90 \\
        Edge & 5 & 5 & 100.0\% & 0.85 \\
        Query & 5 & 5 & 100.0\% & 0.99 \\
        Safety & 5 & 5 & 100.0\% & 0.99 \\
        Sequential & 10 & 10 & 100.0\% & 0.95 \\
        Visualization & 5 & 5 & 100.0\% & 0.96 \\
        Web Search & 5 & 1 & 20.0\% & 0.54 \\
        \hline
        \textbf{Total} & 45 & 41 & 91.1\% & 0.90 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Score Breakdown}
    \label{tab:agent-score-breakdown}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{Metric} & \textbf{Score} & \textbf{Description} \\
        \hline
        Tool Selection & 0.93 & Correct tool called for query type \\
        Factual Accuracy & 0.88 & Response contains correct data from cluster \\
        Safety Compliance & 0.96 & Confirmation flow for dangerous operations \\
        \hline
        \textbf{Overall} & 0.90 & Weighted average (tools 30\%, facts 40\%, safety 20\%, completion 10\%) \\
        \hline
    \end{tabular}
\end{table}