% Auto-generated by evaluate_agent.py

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Results by Category}
    \label{tab:agent-eval-results}
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Category} & \textbf{Tests} & \textbf{Passed} & \textbf{Pass Rate} & \textbf{Avg Score} \\
        \hline
        Web Search & 5 & 2 & 40.0\% & 0.61 \\
        \hline
        \textbf{Total} & 5 & 2 & 40.0\% & 0.61 \\
        \hline
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Agent Evaluation Score Breakdown}
    \label{tab:agent-score-breakdown}
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{Metric} & \textbf{Score} & \textbf{Description} \\
        \hline
        Tool Selection & 0.73 & Correct tool called for query type \\
        Factual Accuracy & 0.36 & Response contains correct data from cluster \\
        Safety Compliance & 1.00 & Confirmation flow for dangerous operations \\
        \hline
        \textbf{Overall} & 0.61 & Weighted average (tools 30\%, facts 40\%, safety 20\%, completion 10\%) \\
        \hline
    \end{tabular}
\end{table}